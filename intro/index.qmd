---
lang: de
title: Einführung
---

# Beteiligte

Die hier thematisierten Daten dienen der Vorbereitung, Durchführung und Auswertung der [VERA](https://www.iqb.hu-berlin.de/vera)-Tests.

## IQB

Das IQB entwickelt die Testaufgaben und legt die Abfolge der Aufgaben innerhalb von Testblöcken (hier "Module") fest. Für die Items wurden während der Pilotierung psychometrische Kennwerte ermittelt. Diese Kennwerte beschreiben die Schwierigkeit eines Items und sind nötig für die Ermittlung der Kompetenzschätzwerte auf Personenebene.

Im Rahmen der Aufgabenentwicklung und -pilotierung sind in einer IQB-internen Datenbank Metadaten und Kennwerte gespeichert. Das IQB erzeugt einen Datenauszug, der im Rahmen dieser Dokumentation spezifiziert ist und veröffentlicht diese Daten an dieser Stelle bei GitHub für die Länder.

## Länder bzw. auswertende Einrichtungen

Die Länder bzw. beauftragte Einrichtungen laden diese Daten herunter und bereiten sie für eigene Zwecke auf. Folgende Verwendungen (sog. use cases) bestimmen diese Aufbereitung:

* Erstellung von Webformularen für die Antworteingabe durch Lehrkräfte: Bei VERA werden die Antworten durch die Lehrkräfte nach der Durchführung gesichtet, bewertet und an eine zentrale Stelle gemeldet. Um die dafür nötigen Webformulare zu erstellen, sind Informationen über die Items und deren Platzierung in den Modulen bzw. Testheften nötig.
* Schätzung der Personenparameter: Für jede Testperson wird ein Kompetenzniveau berechnet. Dies bezieht sich auf eine globale (z. B. Mathematik) oder eine Teilkompetenz (Deutsch Leseverstehen). Für diese Berechung sind die Itemparameter (Logits) sowie Transferparameter erforderlich.
* Rückmeldung Richtig/Falsch auf Aufgabenebene: Teil der Rückmeldung an die Lehrkräfte ist die Anzeige, welche Schülerinnen und Schüler eine Aufgabe richtig oder falsch beantwortet haben. Diese Anzeige wird gewichtet mit den Lösungshäufigkeiten der Items.
* Kategorisierung der Rückmeldedaten über Metadaten: Für einen genaueren Blick auf die Lösungen ist es wichtig, die Zuordnung der Items zu Metadaten (z. B. Bildungsstandards) zu kennen.


# Datenstruktur

```{mermaid}
flowchart LR
    S[Konstanten] -.- A[Aufgabe]
    style S fill:white
    I[Item] --> A
    I -.- S
    A --> M[Vokabulare]
    I --> M
    D[Module] --> A
    D --> I
    D -.- S
    B[Testheft] --> D
```

Die Daten sind in fünf Listen geordnet, die jedes Jahr pro Fach neu erzeugt werden:

* Aufgaben enthalten jeweils Titel, Kennung und wenige Metadaten.
* Items enthalten die psychometrischen Kennzahlen sowie Metadaten.
* In Modulen ist gespeichert, welche Aufgabe und welche Items nacheinander in den Testblöcken platziert sind.
* Testhefte enthalten einen kompletten Testablauf und bestehen aus Modulen. 
* Die Metadaten in den Aufgaben und Items verweisen auf Vokabulare (Wertelisten), die stets neu aktualisiert beim Datenauszug mit ausgegeben werden (z. B. Bildungsstandards).

Spezielle Konstanten werden genutzt, um die Datenstruktur zu vereinfachen. Diese werden nicht neu erzeugt, da sie fester Bestandteil der [Spezifikation](../data-specs-guide/index.qmd) sind.

# Weiterentwicklung

Die vorliegenden Daten ergeben sich aus dem Datenbestand, der aktuell in der Itemdatenbank des IQB verfügbar ist. Folgende weitere Informationen werden demnächst zusätzlich bereitgestellt:

* Metadaten für Module: Bisher ist nur die ID eines Moduls verfügbar. Günstiger für die Datenverarbeitung wäre es, wenn die Art des Moduls (Basis-/Ergänzungsmodul) und weitere Metadaten bereitgestellt werden.
* Transferparameter: Für jedes Fach und mitunter Domäne werden jedes Jahr Parameter an die Länder gegeben, die für die Transformation der empirischen Werte auf die Metrik der Bildungsstandards erforderlich sind.
* Schwellenwerte der Kompetenzstufen: Für jedes Fach und mitunter Domäne werden jedes Jahr die Schwellenwerte für die einzelnen Kompetenzstufen des Kompetenzstufenmodells an die Länder gegeben. Diese sind zwar grundsätzlich konstant, könnten sich aber unter besonderen Umständen ändern.

Außerdem sollen die vorliegenden JSON-Schema-Spezifikationen genutzt werden, um eine Datendatei nach einem Upload zu validieren. So soll sichergestellt werden, dass alle Datendateien verlässlich der Spezifikation entsprechen.
